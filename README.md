# Description
This week I setup a SQL database to manage all the data generated by the simulations. It is a simple relational database with a relation for the paramters under which the simualtion was run (essentially stores the information in the JSON file) and another relation for the data points in the simulation. This second relation stores the 6-vector describing the foot's state along with the time and the corresponding 3-vector GRF. I think the database will help manage the data as it grows. The initial conditions for the simulation that Juntao gave me took about 1.5 hours to run a 4-second simulation (on the GPU) so avoiding resimulating data is important. Last week we did talk about cutting down on the size and number of granular particles so that should help reduce the run time too.

I also worked on visualizing the data generated from the simulation. I used Python and it's graphics library. Since this is a planar animation, I take the (angle of foot, foot's x position, foot's y-position) and use rotation matrices to rotate and translate the frame. At each time step I plot the center's of the foot's position as a red dot. A video of the foot translating along a sinusoidal path and rotating at constant angular velocity is at footRotating.mkv.

The first 0.5 seconds of the simulation have the foot stand still and wait for the granular material to settle. I then animated the first 0.5 second of the foot movingafter that and obtained the following. An image is below. The scale of movement is about 0.01 - 0.1 m in the vertical direction. The visualization tool is in the file vis_motion.py  
 
![alt text](https://github.com/PeterJochem/Chrono_Simulations/blob/master/smallVis.png "0.5 Second Visualization")

I think the visualizer shows that the simulation is qualitatively correct. It acts plausibly, at least to a visual inspection 

# Next Week
1) Change parameters of granular material. Did Juntao find a better parameter? 

2) Run a simulation with in Chrono and use the neural network's predictions to compute the GRF. I have a way to visualize the movement now with the tool I wrote as well as an easily trainable neural network. The network attains low average loss function values. But, a better way to validate it is to use the network in a Chrono simulation and instead of letting Chrono compute the GRF, have the neural network compute it. Then I can visualize the result with my visualization tool. This could serve as a better way to validate the predictions than simply showing the network's average loss.  

Compare neural network's predicted GRF with Dan's RFT-based GRFs?

# Notes to Self
